<!DOCTYPE html>
<head>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG">
</script>
<head
<html lang="en" class="cufon-active cufon-ready"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>§</title>
  <link rel="stylesheet" href="../css/main.css" type="text/css" media="screen">
<style type="text/css">.cufon-canvas{text-indent:0!important;}@media screen,projection{.cufon-canvas{display:inline!important;display:inline-block!important;position:relative!important;vertical-align:middle!important;font-size:1px!important;line-height:1px!important;}.cufon-canvas .cufon-alt{display:-moz-inline-box!important;display:inline-block!important;width:0!important;height:0!important;overflow:hidden!important;text-indent:-10000in!important;}.cufon-canvas canvas{position:relative!important;}}@media print{.cufon-canvas{padding:0!important;}.cufon-canvas canvas{display:none!important;}.cufon-canvas .cufon-alt{display:inline!important;}}</style>
<style>
table, th, td {
    text-align: center;
}
</style>
<style>
p {
  margin-top: 0em;
  margin-bottom: 1.5em;
}
pre {
    white-space: pre-wrap;
}
</style>


<body>
 
    <p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;23&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>
<br><br><br>
 
<p>
6)
<br><br>
<em> Two people are engaged in a joint project. If each person \(i\) puts in the effore \(x_i\), a non-negative number equal to at most \(1\), which costs her \(x_i^2\), the outcome of the project is worth \(\alpha x_1 x_2\), where \(\alpha>2\) is a constant. The worth of the project is split equally between the two people, regardless of their effort levels. </em>
<br><br>
(b)
<br><br>
<em> 
Then find the values of \(\alpha>2\) for which there exists a Nash equilibrium of the game that is inefficient.
</em>
<br><br>
Let's start with the easy question first.
<br><br>
A <em>Nash equilibrium</em> is a strategy profile \((x_1,x_2)\) of effort levels such that each player's strategy is a best response to his opponents strategy.
<br><br>
Regardless of the value of \(\alpha\), it is a Nash equilibrium for both players to exert zero effort.
<br><br>
For \(\alpha>2\), this Nash equilibrium is Pareto dominated by, for example, both players exerting maximal effort, since \(\alpha/2 - 1 > 0\).
<br><br>
(a)
<br><br>
<em> 
Find the values of \(\alpha>2\) for which all Nash equilibria of the game are inefficient. That is, there exists a pair of effort levels that yield higher payoffs for both players than any Nash equilibrium effort levels. 
</em>
<br><br>
We first compute the Nash equilibria.
<br>
<br>
Given \(x_2\) in \([0,1]\), player \(1\)'s marginal benefit of effort is \(\alpha x_2/2\) and player \(2\)'s marginal cost of effort is \(2x_1\).
<br>
<br>
Therefore, \(1\)'s best response to \(x_2\) is \(\alpha x_2/4\) when this is in \((0,1)\) and \(0\) or \(1\) when this quantity is outside \((0,1)\).
<br>
<br>
This can be summarized as \(B_1(x_2) = \min(\alpha x_2/4,1)\).
<br>
<br>
Likewise, \(B_2(x_1) = \min(\alpha x_1/4,1)\).
<p>

<div class="container">
<img src="6(a=2).png" />
</div> 

<div class="container">
<img src="6(a=4).png" />
</div> 

<div class="container">
<img src="6(a=6).png" />
</div> 



<p>



This implies that both players exerting minimal effort is the unique Nash equilibrium when \(\alpha\) is in \((2,4)\), since the best response to one player's effort level is a lower effort level.
<br>
<br>
When \(\alpha = 4\) any pair of equal effort levels is a Nash equilibrium.
<br>
<br>
When \(\alpha > 4\) there are two Nash equilibira: one where both players exert maximal effort, and one where both players exert maximal effort.
<br>
<br>
The final step is to show that there is no pair of effort levels that Pareto dominate both players putting in maximal effort. 
<br>
<br>
This can be seen by noting that, for \(\alpha\geq 4\), total output less costs is maximized when both players exert maximal effort.
<br>
<br>




8) 
<br><br>
<em> There are two routes for driving from \(A\) to \(B\). One is the motorway, and the other consists of local roads. The benefit of using the mororway is constant ans equal to 1.8, irrespective of the number of people using it. Local roads get congested when too many people use them, but if too few people use them, the few isolated drivers run the risk of becoming victims of crime. Suppose that when a fraction \(x\) of the population uses local roads, the benefit of this mode to each driver is given by:
\[
1 + 9x - 10x^2
\]
Throughout this question suppose that there is an infinite number of people such that \(x\) is a continuous variable that can range from \(0\) to \(1\).</em>
<br><br>
(a)
<br><br>
<em> Draw a graph showing the benefits of the two driving routes as functions of \(x\).
</em>
<p>

<div class="container">
<img src="8(a).png" />
</div> 


<p>
(b)
<br><br>
<em> Identify all possible equilibrium traffic patterns fromm your graph. You should find three. Are any of these equilibria less likely to be played than the others?
</em>
<br><br>
If \(x\) is in \((0,1)\), it must be that all agent's are indifferent between local roads and the motorway
<br>
<br>
It is an equilibrium for everyone to take the motorway. This equilibrium is stable since if a small fraction take local roads, they do worse and so have an incentive to switch back.
<br>
<br>
It is an equilibrium for the fraction 0.1 of the population to take local roads. This equilibrium is unstable since if a small fraction deviate from the motorway to local roads, they do better. Likewise, if a small fraction deviates from local roads to the motorway those that remain on the local roads do worse, and so have an incentive to deviate also.
<br>
<br>
It is an equilibrium for the fraction 0.8 to take local roads. This equilibrium is stable. If a small fraction deviate from the motorway to local roads, they do worse. If a small fraction deviate from local roads to the motorway, local roads become more attractive and so there is an incentive to switch back to local roads.

<br>
<br>
(c)
<br><br>
<em> What value of \(x\) maximizes the total benefit to the whole population? How might this be achieved?
</em>
<br><br>
Small fraction more take local roads, incentive to switch back. Small fraction less take local roads, incentive for more to take local roads. Stable.
<br>
<br>
Bonus: What if one agent has non-negligable mass of 0.05?
<br>
<br>
\(x^*=0.5516\) maximizes welfare \(1.8(1 − x) + x(1 + 9x − 10x^2)\)
<br>
<br>
Can impose a quota on local road use of \(x^*\), or else
tax local road use (or subsidise motorway use) to make people indifferent
between using both routes when \(x = x^*\)
<br>
<br>


7) 
<br><br>
<em> Two individuals are considering undertaking a business venture that will earn them $100 in profit, but they must agree how to split the $100. The two individuals agree to simultaneously make a non-negative demand, If their demands sum to more than $100, they fail to agree, don't undertake the venture and each gets nothing. If their demands sum to less than $100, they do the project, each gets his demand, and the rest goes to charity (which neither values).
</em>
<br><br>

(a)
<br><br>
<em> What are each player's strictly dominated strategies?</em>
<br><br>
A strategy \(x_i\) is <em>strictly dominated</em> if there is a strategy \(x_i'\) that always does better.
<br>
<br>
In this game, no strategy can always do better than any other since if the opponent bids more than \(100\), every strategy delivers a payoff of \(0\). 
<br>
<br>
Therefore, there are no strictly dominated strategies. 
<br>
<br>
(b)
<br><br>
<em> What are each player's weakly dominated strategies?</em>
<br><br>
A strategy \(x_i\) is <em>weakly dominated</em> if there is a strategy \(x_i'\) that always does at least as well.
<br>
<br>
Bids that are \(0\) or greater than \(100\) are weakly dominated because they gaurentee the minimal payoff of \(0\).
<br>
<br>
Consider a bid \(x_i\) in \((0,100]\).
<br>
<br>
If \(x_j=100-x_i\), then \(x_i\) does better than any other bid \(i\) could make.
<br>
<br>
Therefore, \(x_i\) cannot be a weakly dominated strategy.
<br>
<br>
(c)
<br>
<br>
<em> What are the Nash equilibrium of this game?</em>
<br>
<br>
A <em>Nash equilibrium</em> is a strategy profile \((x_1,x_2)\) such that each player's strategy is a best response to their opponents' strategies.
<br>
<br>
Each pair of bids \((x_1,x_2)\) with \(x_1+x_2 = 100 \) or \(x_1,x_2 \geq 100\) is a Nash equilibrium.
<br>
<br>
If \(x_1+x_2 < 100 \), each player has an incentive to increase their bid.
<br>
<br>
If \(x_1+x_2 > 100 \) and either \(x_1 < 100\) or \(x_2 < 100\), then there is a player with an incentive to devate so that the total bid is \(100\).
<br>
<br>


5)


<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>L</th>
    <th>M</th>
    <th>R</th>
  </tr>
  <tr>
    <th>U</th>
    <td>\(2,2\)</td>
    <td>\(1,3\)</td>
    <td>\(0,1\)</td>
  </tr>
  <tr>
    <th>C</th>
    <td>\(3,1\)</td>
    <td>\(0,0\)</td>
    <td>\(0,0\)</td>
  </tr>
   <tr>
    <th>D</th>
    <td>\(1,0\)</td>
    <td>\(0,0\)</td>
    <td>\(0,0\)</td>
  </tr>
</table>
<br>
<br>

Neither player has a dominant strategy. However, the game is symmetric so the best response correspondences will be too.
<br>
<br>
Player \(1\)'s best response correspondence is
<br>
<br>
\[
BR_1(\textbf{L}) = \{\textbf{C}\}\text{,  } BR_1(\textbf{M}) = \{\textbf{U}\}\text{,  } BR_1(\textbf{R}) = \{\textbf{U},\textbf{C},\textbf{D}\}
\]
<br>
<br>
Player \(2\)'s best response correspondence is
<br>
<br>
\[
BR_2(\textbf{U}) = \{\textbf{M}\}\text{,  } BR_2(\textbf{C}) = \{\textbf{L}\}\text{,  } BR_2(\textbf{D}) = \{\textbf{L},\textbf{M},\textbf{R}\}
\]
<br>
<br>
We can immeiatly see that \((\textbf{R},\textbf{B})\) is a Nash equilibrium since
<br>
<br>
\[
(\textbf{R},\textbf{D}) \in BR_1(\textbf{D}) \times  BR_2(\textbf{R})
.\]
<br>
<br>
Likewise, \((\textbf{U},\textbf{M})\) and \((\textbf{C},\textbf{L})\) are Nash equilibria since
<br>
<br>
\[
(\textbf{U},\textbf{M}) \in BR_1(\textbf{M}) \times  BR_2(\textbf{U})
\]
\[
(\textbf{C},\textbf{L}) \in BR_1(\textbf{L}) \times  BR_2(\textbf{C})
\]
<br>
<br>

4)

<br>
<br>
A player \(i\)'s <em>best response correspondence</em> is a function mapping opponents' strategy choice to the set of \(i\)'s "best responses".

<br>
<br>
<b>Prisoners' Dilemma</b>:

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>cooperate</th>
    <th>defect</th>
  </tr>
  <tr>
    <th>cooperate</th>
    <td>\(2,2\)</td>
    <td>\(0,3\)</td>
  </tr>
  <tr>
    <th>defect</th>
    <td>\(3,0\)</td>
    <td>\(1,1\)</td>
  </tr>
</table>
<br>
<br>

The game is symmetric, so both players have the same best response correspondence. Moreover, the best response correspondence is constant because each player has a strictly dominant strategy.
<br>
<br>
\[
BR(\textbf{cooperate}) = \{\textbf{defect}\}\text{,  } BR(\textbf{defect}) = \{\textbf{defect}\}
\]
<br>
<br>

<b>Battle of Sexes</b>:

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>ballet</th>
    <th>soccer</th>
  </tr>
  <tr>
    <th>ballet</th>
    <td>\(2,1\)</td>
    <td>\(0,0\)</td>
  </tr>
  <tr>
    <th>soccer</th>
    <td>\(0,0\)</td>
    <td>\(1,2\)</td>
  </tr>
</table>
<br>
<br>

Again this game is symmetric, so both players have the same best response correspondence. 
<br>
<br>
\[
BR(\textbf{ballet}) = \{\textbf{ballet}\}\text{,  } BR(\textbf{soccer}) = \{\textbf{soccer}\}
\]
<br>
<br>
<b>Penny Matching</b>:

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>heads</th>
    <th>tails</th>
  </tr>
  <tr>
    <th>heads</th>
    <td>\(1,-1\)</td>
    <td>\(-1,1\)</td>
  </tr>
  <tr>
    <th>tails</th>
    <td>\(-1,1\)</td>
    <td>\(1,-1\)</td>
  </tr>
</table>
<br>
<br>

Player \(1\)'s best response correspondence is
<br>
<br>
\[
BR_1(\textbf{heads}) = \{\textbf{heads}\}\text{,  } BR_1(\textbf{tails}) = \{\textbf{tails}\}
\]
<br>
<br>
Player \(2\)'s best response correspondence is
<br>
<br>

\[
BR_2(\textbf{heads}) = \{\textbf{tails}\}\text{,  } BR_2(\textbf{tails}) = \{\textbf{heads}\}
\]
<br>
<br>
There aren't any Nash equlibria.
<br>
<br>
<b>Stag Hunt</b>:

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>stag</th>
    <th>hare</th>
  </tr>
  <tr>
    <th>stag</th>
    <td>\(2,2\)</td>
    <td>\(0,1\)</td>
  </tr>
  <tr>
    <th>hare</th>
    <td>\(1,0\)</td>
    <td>\(1,1\)</td>
  </tr>
</table>
<br>
<br>

Both players have the same best response correspondence. 
<br>
<br>

\[
BR(\textbf{stag}) = \{\textbf{stag}\}\text{,  } BR(\textbf{hare}) = \{\textbf{hare}\}
\]
<br>
<br>

To verify the Nash equilibria of each game we need to check that at the proposed Nash equilibrium each player's strategy is a best response to their opponents strategy. 

<br>
<br>
For example, in Prisoners' Dilemmam to verify that \((\textbf{defect},\textbf{defect})\) is a Nash equilibrium we check that
<br>
<br>
\[
(\textbf{defect},\textbf{defect}) \in BR(\textbf{defect}) \times  BR(\textbf{defect})
,\]
<br>
<br>
which it is. The other cases are similarly straightforward.
<br>
<br>

3)

<br>
<br>

Again, it is a good idea to explicitly write down the three elements of the game: players, strategies, and payoffs. 
<br>
<br>
In this case, the resulting payoff matrices might look like

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>aggressive</th>
    <th>passive</th>
  </tr>
  <tr>
    <th>aggressive</th>
    <td>\(0,0\)</td>
    <td>\(3, 1\)</td>
  </tr>
  <tr>
    <th>passive</th>
    <td>\(1,3\)</td>
    <td>\(2,2\)</td>
  </tr>
</table>

<br>
<br>
Notice that the description implies that both being passive Pareto dominates both being aggressive.

<br>
<br>

There are two Nash equilibria, in each one player being aggressive and the other passive. 

<br>
<br>

2) (b)

<br>
<br>

Reversing the order of payoffs does the trick.

<br>
<br>
When both players prefer standing alone to standing together, we get
<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(1, 3\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(3,1\)</td>
    <td>\(0,0\)</td>
  </tr>
</table>

<br>
<br>

When both players prefer standing together to standing alone, we get

<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(0, 3\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(3,0\)</td>
    <td>\(1,1\)</td>
  </tr>
</table>

<br>
<br>

When the row player prefers standing together to standing alone and the column player prefers standing alone to standing together, we get 
<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(1, 3\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(3,0\)</td>
    <td>\(0,1\)</td>
  </tr>
</table>

<br>
<br>

In the first case, there is no Nash equilibrium (recall we are only considering pure strategies).
<br>
<br>
In the second case, the unique Nash equilibrium is for both players to stand. Indeed, "stand" is a strictly dominant strategy for both players.
<br>
<br>
In the last case, the column player has a strictly dominant strategy to stand. Consequently, the Nash equilibrium is for the row player to sit and the column player to stand.  
<br>
<br>
The question asks only about the second case.
<br>
<br>
We are also asked to compare "equilibrium levels of comfort" in the two games. 
<br>
<br>
All that can be said is that the Nash equilibrium is now Pareto inefficient—it is a Pareto improvement for both people to sit.
<br>
<br>

Bonus question. what if both players realize their opponent cares about their own preferences. How can we model this situation?
  <br>
<br>
2) (a) 
<br>
<br>
A strategic form game has three elements: players, strategies, and payoffs. To be 
careful it is good idea to write out this information step by step. 

Under the anti-social assumption that standing alone is preferred to standing together the payoff matrices look something like
<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(3, 1\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(1,3\)</td>
    <td>\(0,0\)</td>
  </tr>
</table>
<br>
<br>

If, instead, standing together is universally preferable to standing alone we get something like
<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(3, 0\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(0,3\)</td>
    <td>\(1,1\)</td>
  </tr>
</table>

<br>
<br>

The other possibility is that the players are asymmetric in their preferences for standing with or without the other person. Supposing that the row player is the sociable one, we get something like
<br>
<br>
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>sit</th>
    <th>stand</th>
  </tr>
  <tr>
    <th>sit</th>
    <td>\(2,2\)</td>
    <td>\(3, 1\)</td>
  </tr>
  <tr>
    <th>stand</th>
    <td>\(0,3\)</td>
    <td>\(1,0\)</td>
  </tr>
</table>

<br>
<br>

The <em>Nash equilibium</em> in all cases is that both players sit, because in all cases "sit" is a <em>strictly dominant strategy</em> for each player.
<br>
<br>
A "Prisoners' Dilemma" is any two player two strategy game where both players have a strictly dominant strategy which leads to payoffs that are Pareto dominated by the payoffs achieved by both players playing the alternative strategy. 
<br>
<br>
This game is not a Prisoners' dilemma because standing together does not Pareto dominate sitting together.
<br>
<br>
Put differently, Adam Smith's invisible hand works in that it leads to a <em>Pareto optimal</em> outcome (i.e. an outcome that is not Pareto dominated).
<br>
<br>


  
1) 

<br>
<br>
"Prisoners' Dilemma" runs counter to Adam Smith's idea that pursuing private interest promotes social good: defecting is a <em>strictly dominant strategy</em> for each prisoner but leads to an outcome that is <em>Pareto dominated</em> by cooperation. 
<br><br>
Any two-strategy, two-player game where this is the case is a Prisoners' Dilemma. For example, \(\text{strategy }2\) is strictly dominant for each player if
<br>
\[
(\text{strategy }2,\text{strategy }1) \succ_1 (\text{strategy }1,\text{strategy }1) \text{, } (\text{strategy }2,\text{strategy }2) \succ_1 (\text{strategy }1,\text{strategy }2),
\]


\[
(\text{strategy }1,\text{strategy }2) \succ_2 (\text{strategy }1,\text{strategy }1) \text{, } (\text{strategy }2,\text{strategy }2) \succ_2 (\text{strategy }2,\text{strategy }1)
\]

and both playing \(\text{strategy }2\) is Pareto dominated by both playing \(\text{strategy }1\) if
<br>


\[ 
(\text{strategy }1,\text{strategy }1) \succ_1 (\text{strategy }2,\text{strategy }2),
\]

\[ 
(\text{strategy }1,\text{strategy }1) \succ_2 (\text{strategy }2,\text{strategy }2).
\]

The question asks you to reimagine a world in which a cartel punishes defection so that, in particular, cooperation becomes a dominant strategy. Obviously the result will be that both prisoners cooperate. 
<br>
<br>
In the peculiar wording of the problem, each prisoner now prefers <em>any</em> amount of jail time than to defect, and thus the resulting game must go from something like


<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>cooperate</th>
    <th>defect</th>
  </tr>
  <tr>
    <th>cooperate</th>
    <td>\(1,1\)</td>
    <td>\(3, 0\)</td>
  </tr>
  <tr>
    <th>defect</th>
    <td>\(0,3\)</td>
    <td>\(2,2\)</td>
  </tr>
</table>
<br>

to

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>cooperate</th>
    <th>defect</th>
  </tr>
  <tr>
    <th>cooperate</th>
    <td>\(1,1\)</td>
    <td>\(3, \infty\)</td>
  </tr>
  <tr>
    <th>defect</th>
    <td>\(\infty,3\)</td>
    <td>\(\infty,\infty\)</td>
  </tr>
</table>

<br>
where payoffs are in years of prison time.
<br>
<br>

Bonus 1: what happens if before having to choose cooperate or defect, the players can  together observe the outcome of a coin toss? Model the game again. How does the set of strategies change? What are the Nash equilibria of this game? What if the players separately observe a coin toss.

<br>
<br>

Bonus 1: what are the mixed strategy equilibria? what do they mean?


  
</p>
  
   <p>
   
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;19&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>
  
 <p> 
 Single neuron. Specify threshold for action potential. Input is a pixel's intensity. Output is binary, predicting if pixel is black or white. Set threshold to minimize a loss function. Separate text from non text. Two neurons. Four outputs. Inputs from two dimensions. (Output could be something like neurotransmitter.) Simple case: Continuous one dimensional input (for example, the intensity of a pixel, the number of incoming signals), output a probability of a binary signal. Discard primitive layers once you have learned to recognize entire words in one go.
 </p>  
   
<div class="container">
<img src="test_page.png" />
</div> 


  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;18&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

Exploiting inattention. Designing resolution of uncertainty for multiple people. Undesirable information. Communicating to the subconcious (covert inception of an idea), suspicion of ulterior meaning.


</p>  
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;17&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

 <font size="2">
<pre><code>  
#generalized_birkhoff_von_neumann.py decomposes a matrix into a weighted average of basis matrices with integer coefficients
#satisfying imposed constraints. When the starting matrix is doubly stochastic and the basis matrices are restricted to
#be permutation matrices, this is the classical birkhoff_von_neumann decomposition. Formally, we implement the algorithm 
#identified in Budish, Che, Kojima, and Milgrom (2013). Thus, the constraint structure must form what they call a bihierarchy.
#
# Copyright 2017 Aubrey Clark.
#
# generalized_birkhoff_von_neumann is free software: you can redistribute it and/or modify it under the
# terms of the GNU General Public License as published by the Free Software
# Foundation, either version 3 of the License, or (at your option) any later
# version.

#: The current version of this package.
__version__ = '0.0.1-dev'

import networkx as nx
import numpy as np
import copy
import itertools
import math
from pprint import pprint

#numbers in some arrays will be rounded to the nearest integer if within the following tolerance
tolerance = np.finfo(np.float).eps * 10

#Example matrix and constraint structures. X is the matrix we wish to decompose into a weighted
#average of basis matrices. constraint_structure is a dictionary whose keys are subsets of coordinates of the basis matrices
#(the dimensions of which are the same as X) (e.g. frozenset({(0, 0), (0, 1), (0,2)})) refers to the (0,0),(0,1),(0,2) 
#coordinates), and whose keys refer to the minimum and maximum sum of these entries in each of the basis matrices 
#(e.g. the value (1,1) means that the coordinates that this value's key represents sum to exactly one in each 
#of the basis matrices.)

#X = np.array([[.5, .2,.3], [.5,.5, 0], [.8, 0, .2], [.2, .3, .5]])
#constraint_structure = {frozenset({(0, 0), (0, 1), (0,2)}): (1,1), frozenset({(1, 0), (1, 1), (1,2)}):(1,1), frozenset({(2, 0), (2, 1), (2,2)}):(1,1), frozenset({(3, 0), (3, 1), (3,2)}):(1,1), frozenset({(0, 0), (1, 0), (2,0), (3,0)}):(1,2),  frozenset({(0, 1), (1, 1), (2,1), (3,1)}):(1,1), frozenset({(0, 2), (1, 2), (2,2), (3,2)}):(1,1), frozenset({(0, 0), (1, 0)}):(1,1)}

#X = np.array([[.3, .7], [.7,.3]])
#constraint_structure = {frozenset({(0, 1),(1,0)}): (1,1), frozenset({(1, 0),(1,1)}): (1,1)}

#bihierarchy_test decomposes the constraint structure into a bihierarchy if it is one. if the constraint structure is not
#a bihierarchy or the matrix X does not satisfy the constraint structure to begin with, then bihierarchy_test will tell you 
#this. bihierarcyy_test shall be invoked by generalized_berkhoff_con_neumann_decomposition, and so the latter function
#(which performs the decomposition) will also warn about these issues.

def bihierarchy_test(X, constraint_structure):
  for key, value in constraint_structure.items():
    if sum([X[i] for i in key]) < value[0] or sum([X[i] for i in key]) > value[1]:
      print("impossible constraint structure capacities")
  C = []
  for key, value in constraint_structure.items():
    C.append(set(key))
  permutations =  itertools.permutations(C)
  for c in permutations:
    listofA, listofB = [], []
    for idx, x in enumerate(c):
      if all( x < y or y < x or x.isdisjoint(y) for y in [c[i] for i in listofA]):
        target = listofA
      elif all(x < y or y < x or x.isdisjoint(y) for y in [c[i] for i in listofB]):
        target = listofB
      else:
        break
      target.append(idx)
    if len(listofA) + len(listofB) == len(c):
      return [[c[i] for i in listofA], [c[i] for i in listofB]]
    else:
      print("constraint structure cannot be decomposed into a bihierarchy")

#generalized_birkhoff_von_neumann_iterator is the core step in the decomposition. After the starting matrix X and the
#constraint structure have been represented as a weighted, directed graph G, this function takes as input a list H = [(G,p)]
#(where p is a probability, which is initially one) and will decompose the graph into two such graphs, 
#each with an associated probability, and each of which are closer to representing a basis matrix.
#Seqential iteration, which is done in the main function generalized_birkhoff_von_neumann_decomposition, leads to the final
#decomposition
      
def generalized_birkhoff_von_neumann_iterator(H):
  tolerance = np.finfo(np.float).eps * 10
  #
  (G, p) = H.pop(0)
  #
  #remove edges with integer weights
  #extracts all edges satisfy the weight threshold:
  #
  eligible_edges = [(from_node,to_node,edge_attributes) for from_node,to_node,edge_attributes in G.edges(data=True) if all(i+tolerance < edge_attributes['weight'] or edge_attributes['weight'] < i - tolerance for i in range(0,math.floor(sum(sum(X) ) ) ) ) ]
  #
  K = nx.DiGraph()
  K.add_edges_from(eligible_edges)
  #
  #find a cycle and compute the push_forward and push_reverse probabilities and graphs
  cycle = nx.find_cycle(K, orientation='ignore')
  forward_weights = [(d['weight'],d['min_capacity'],d['max_capacity']) for (u,v,d) in K.edges(data=True) if (u,v,'forward') in cycle]
  reverse_weights = [(d['weight'],d['min_capacity'],d['max_capacity']) for (u,v,d) in K.edges(data=True) if (u,v,'reverse') in cycle]
  push_forward = min((x[2] - x[0] for x in forward_weights))
  push_reverse = min((x[2] - x[0] for x in reverse_weights))
  pull_forward = min((x[0] - x[1] for x in forward_weights))
  pull_reverse = min((x[0] - x[1] for x in reverse_weights))
  push_forward_pull_reverse = min(push_forward,pull_reverse)
  push_reverse_pull_forward = min(pull_forward,push_reverse)
  #
  #Construct the push_forward_pull_reverse graph
  #
  G1 = copy.deepcopy(G)
  for u,v,d in G1.edges(data=True):
    if (u,v,'forward') in cycle:
      d['weight']+=push_forward_pull_reverse
    if (u,v,'reverse') in cycle:
      d['weight']+=-push_forward_pull_reverse
  #
  #Construct the push_reverse_pull_forward graph
  #
  G2 = copy.deepcopy(G)
  for u,v,d in G2.edges(data=True):
    if (u,v,'reverse') in cycle:
      d['weight']+=push_reverse_pull_forward
    if (u,v,'forward') in cycle:
      d['weight']+=-push_reverse_pull_forward
  #
  gamma = push_reverse_pull_forward/(push_forward_pull_reverse + push_reverse_pull_forward)
  return([(G1,p*gamma), (G2,p*(1-gamma))])

#generalized_birkhoff_von_neumann_decomposition takes the primitives, a starting matrix X (a numpy array) and
#a constraint structure constraint_structure (a dictionary, whose structure is described in the examples above).
#First, it applies bihierarchy_test to these primitives (see above for what this does). Then, if all is okay at the
#first step, it represents these primitives as a weighted, directed graph and then iteratively applies 
#generalized_birkhoff_von_neumann_iterator. Finally, it cleans the solution, transforming the
#final iteration directed, weighted graphs to basis matrices, merging duplicate basis matrices and their probabilities,
#checking that the probabilities form a distribution, and checking that the average of the basis matricies under this
#distribution is indeed the starting matrix X

def generalized_birkhoff_von_neumann_decomposition(X,constraint_structure):
  #
  tolerance = np.finfo(np.float).eps * 10
  S = {index for index, x in np.ndenumerate(X)}
  #
  A,B = bihierarchy_test(constraint_structure)
  A.append(S), B.append(S)
  #
  for x in S:
    A.append({x}), B.append({x})
  #
  for x in S:
    constraint_structure.update({frozenset({x}):(0,1)})
  #
  R1 = nx.DiGraph()
  for x in A:
    for y in A:
      if x < y and not any(x < z < y for z in A):
        R1.add_edge(frozenset(y),frozenset(x),weight=sum([X[i] for i in x]), min_capacity = constraint_structure[frozenset(x)][0], max_capacity = constraint_structure[frozenset(x)][1])
  #
  R2 = nx.DiGraph()
  for x in B:
    for y in B:
      if y < x and not any(y < z < x for z in B):
        R2.add_edge((frozenset(y),'p'),(frozenset(x),'p'),weight = sum( [X[i] for i in y]), min_capacity = constraint_structure[frozenset(y)][0], max_capacity = constraint_structure[frozenset(y)][1])
  #
  G = nx.compose(R1,R2)
  #
  for index, x in np.ndenumerate(X):
    G.add_edge(frozenset({index}), (frozenset({index}),'p'), weight=x, min_capacity = 0, max_capacity = 1)
  #
  H=[(G,1)]
  solution=[]
  #
  while len(H) > 0:
    if any(tolerance < x < 1 - tolerance for x in [d['weight'] for (u,v,d) in H[0][0].edges(data=True) if u in [frozenset({x}) for x in S]]):
      H.extend(generalized_birkhoff_von_neumann_iterator([H.pop(0)]))
    else:
      solution.append(H.pop(0))
  #
  solution_columns_and_probs = []
  #
  for y in solution:
    solution_columns_and_probs.append([[(u,d['weight']) for (u,v,d) in y[0].edges(data=True) if u in [frozenset({x}) for x in S]],y[1]])
  #
  solution_zeroed = []
  #
  for z in solution_columns_and_probs:
    list = []
    for y in z[0]:
      if y[1] < tolerance:
        list.append((y[0],0))
      elif y[1] > 1-tolerance:
        list.append((y[0],1))
    solution_zeroed.append([list,z[1]])
  #
  assgs = []
  coeffs = []
  #
  for a in solution_zeroed:
    Y = np.zeros(X.shape)
    for x in a[0]:
      for y in x[0]:
        Y[y]=x[1]
    assgs.append(Y)
    coeffs.append(a[1])
  #
  list = []
  #
  for idx, x in enumerate(solution_zeroed):
    if all(x[0]!= z[0] for z in [solution_zeroed[i] for i in list]):
      list.append(idx)
  #
  solution_simplified = []
  #
  for i in list:
    solution_simplified.append([solution_zeroed[i][0],sum([x[1] for x in solution_zeroed if x[0]==solution_zeroed[i][0]])])
  #
  assignments = []
  coefficients = []
  #
  for a in solution_simplified:
    Y = np.zeros(X.shape)
    for x in a[0]:
      for y in x[0]:
        Y[y]=x[1]
    assignments.append(Y)
    coefficients.append(a[1])
  #
  pprint([coefficients, assignments, sum(coefficients), sum(i[1]*i[0] for i in zip(coefficients, assignments))])
 </code></pre> </font>
  
   <p>
 <p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;16&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

Program that allows small wagers and commitment contracts between people. Challenge is to verify outcomes. Could let the individuals agree on the outcome. Provide tools to help outcomes be more verifiable, e.g. an arbitrator in the event of disagreement, escrow account, suggested use of correllation with verifiable outcomes (interesting maching learning program in its own right). Needs a good name. Mathing technology: advertize wager (or risk one wants to hedge), shown to people that want to take the other side. Compatability with online currencies. Project partnerships.
<br>
<br>
Predict best way to hedge house price exposure in your area. Optimal composition of stocks and investments. Create a local business performance index, or a local house price index. Trust issue. Correlation could be best. 

<p>





<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;15&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

Experiments on self control, with the laboratory being study sessions in which phones and laptops are taken away, or in which phones are taken away and people are monitored. One treatment: display confiscated phones and laptops. Another treatment: plant people in the room who give up. Another: different commitment contracts: e.g. team comittments, shaming, pro rata incentives.  

<p>

  
  
  <p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;15&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  

<p>
  
1) "Prisoners' Dilemma" runs counter to Adam Smith's idea that pursuing private interest promotes social good: defecting is a <em>strictly dominant strategy</em> for each prisoner but leads to an outcome that is <em>Pareto dominated</em> by cooperation. 
<br><br>
Any two-strategy, two-player game where this is the case is a Prisoners' Dilemma. For example, \(\text{strategy }2\) is strictly dominant for each player if
<br>
\[
(\text{strategy }2,\text{strategy }1) \succ_1 (\text{strategy }1,\text{strategy }1) \text{, } (\text{strategy }2,\text{strategy }2) \succ_1 (\text{strategy }1,\text{strategy }2),
\]


\[
(\text{strategy }1,\text{strategy }2) \succ_2 (\text{strategy }1,\text{strategy }1) \text{, } (\text{strategy }2,\text{strategy }2) \succ_2 (\text{strategy }2,\text{strategy }1)
\]

and both playing \(\text{strategy }2\) is Pareto dominated by both playing \(\text{strategy }1\) if
<br>


\[ 
(\text{strategy }1,\text{strategy }1) \succ_1 (\text{strategy }2,\text{strategy }2),
\]

\[ 
(\text{strategy }1,\text{strategy }1) \succ_2 (\text{strategy }2,\text{strategy }2).
\]

The question asks you to reimagine a world in which a cartel punishes defection so that, in particular, cooperation becomes a dominant strategy. Obviously the result will be that both prisoners cooperate. 
<br>
<br>
In the peculiar wording of the problem, each prisoner now prefers <em>any</em> amount of jail time than to defect, and thus the resulting game must go from something like


<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>cooperate</th>
    <th>defect</th>
  </tr>
  <tr>
    <th>cooperate</th>
    <td>\(1,1\)</td>
    <td>\(3, 0\)</td>
  </tr>
  <tr>
    <th>defect</th>
    <td>\(0,3\)</td>
    <td>\(2,2\)</td>
  </tr>
</table>
<br>

to

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>cooperate</th>
    <th>defect</th>
  </tr>
  <tr>
    <th>cooperate</th>
    <td>\(1,1\)</td>
    <td>\(3, \infty\)</td>
  </tr>
  <tr>
    <th>defect</th>
    <td>\(\infty,3\)</td>
    <td>\(\infty,\infty\)</td>
  </tr>
</table>

<br>
where payoffs are in years of prison time.
  
  <p>
  
  <p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;14&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  
  
<p>
This transforms the assignments to <code>numpy</code> arrays and computes the expected assignment. There seems to be an issue though, because the expected assignment computed here is not equal to \(X\).
<font size="2">
<pre><code>
matrix_solution = []
expected_assignment = []

for a in solution_simplified:
  Y = np.zeros((4,3))
  for x in a[0]:
    for y in x[0]:
      Y[y]=x[1]
  matrix_solution.append([Y,a[1]])
  expected_assignment.append(a[1]*Y)

sum(expected_assignment)
</code>
</pre>
</font>
<p>  
    
    
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;13&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  

<p>
This sets assignment probabilities to zero or one (rather than their approximate values of zero or one) and then combines identical assignments, adding their probabilitiies.

<font size="2">
<pre><code>
solution_columns_and_probs = []

for y in solution:
  solution_columns_and_probs.append([[(u,d['weight']) for (u,v,d) in y[0].edges(data=True) if u in [frozenset({x}) for x in S]],y[1]])

solution_zeroed = []

for z in solution_columns_and_probs:
    list = []
    for y in z[0]:
      if y[1] < tolerance:
        list.append((y[0],0))
      elif y[1] > 1-tolerance:
        list.append((y[0],1))
    solution_zeroed.append([list,z[1]])
  
list = []

for idx, x in enumerate(solution_zeroed):
  if all(x[0] !=  z[0] for z in [solution_zeroed[i] for i in list]):
      list.append(idx)
     
solution_simplified = []
   
for i in list:
  solution_simplified.append([solution_zeroed[i][0],sum([x[1] for x in solution_zeroed if x[0]==solution_zeroed[i][0]])])
</code>
</pre>
</font>

<p>  
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;12&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  
    
<p>

This python code iterates <font size="2"><code>generalized_birkhoff_von_neumann_iterator()</code></font> until the central column of each graph is an assignment.


 
 <font size="2">
<pre><code>
solution=[]

while len(H) > 0:
  if any(tolerance < x < 1 - tolerance for x in [d['weight'] for (u,v,d) in H[0][0].edges(data=True) if u in [frozenset({x}) for x in S]]):
    H.extend(generalized_birkhoff_von_neumann_iterator([H.pop(0)]))
  else:
    solution.append(H.pop(0))
</code></pre></font>

I now want to merge duplicate allocations and their probabilities, check that the average of the assignments is the expected assignment \(X\), and to present the results in a readable form. Below are some pieces for doing this.
  
<font size="2">
<pre><code>  
solution_graphs = []

for x in solution:
  solution_graphs.append(x[0])

solution_columns = []

for y in solution_graphs:
  solution_columns.append([(u,d['weight']) for (u,v,d) in y.edges(data=True) if u in [frozenset({x}) for x in S]])

solution_columns_and_probs = []

for y in solution:
  solution_columns_and_probs.append([[(u,d['weight']) for (u,v,d) in y[0].edges(data=True) if u in [frozenset({x}) for x in S]],y[1]])
</code>
</pre>
</font>

Is there a way to reduce the number of assignments? Would searching for the longest cycle do this?
  
</p>  
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;11&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

The constraint structure is a dictionary whose keys are constraint sets and singleton object-agent pairs, and whose values are the corresponding tuples of minimum and maximum capacity.

  <font size="2">
<pre><code>
import networkx as nx
import numpy as np
import copy
import itertools

C = [{(0, 1), (1, 1)}, {(1, 0), (0, 0)}, {(0, 1), (0, 0), (1, 1)}, {(0, 1), (1, 0), (0, 0)}]
X = np.array([[.4, .6], [.7, .9]])
S = {index for index, x in np.ndenumerate(X)}
constraint_structure_dict = {frozenset({(0, 1), (1, 1)}):(0,2), frozenset({(1, 0), (0, 0)}): (0,2), frozenset({(0, 1), (0, 0), (1, 1)}):(0,3), frozenset({(0, 1), (1, 0), (0, 0)}):(0,3)}

#need to assign the min and max capacity attributes to every edge, except to and from whole set
for x in S:
  constraint_structure_dict.update({frozenset({x}):(0,1)})

#takes the sets of a constraint structure and prints a bihierarchy if one exists

def bihierarchy_test(C):
  permutations =  itertools.permutations(C)
  for c in permutations:
    listofA, listofB = [], []
    for idx, x in enumerate(c):
      if all( x < y or y < x or x.isdisjoint(y) for y in [c[i] for i in listofA]):
        target = listofA
      elif all(x < y or y < x or x.isdisjoint(y) for y in [c[i] for i in listofB]):
        targe = listofB
      else:
        break
      target.append(idx)
    if len(listofA) + len(listofB) == len(c):
      return [[c[i] for i in listofA], [c[i] for i in listofB]]

A,B = bihierarchy_test(C)
A.append(S), B.append(S)

for x in S:
  A.append({x}), B.append({x})

G1 = nx.DiGraph()
for x in A:
  for y in A:
    if x < y and not any(x < z < y for z in A):
      G1.add_edge(frozenset(y),frozenset(x),weight=sum([X[i] for i in x]), min_capacity = constraint_structure_dict[frozenset(x)][0], max_capacity = constraint_structure_dict[frozenset(x)][1])

G2 = nx.DiGraph()
for x in B:
  for y in B:
    if y < x and not any(y < z < x for z in B):
      G2.add_edge((frozenset(y),'p'),(frozenset(x),'p'),weight = sum( [X[i] for i in y]), min_capacity = constraint_structure_dict[frozenset(y)][0], max_capacity = constraint_structure_dict[frozenset(y)][1])

G = nx.compose(G1,G2)

for index, x in np.ndenumerate(X):
  G.add_edge(frozenset({index}), (frozenset({index}),'p'), weight=x, min_capacity = 0, max_capacity = 1)

def generalized_birkhoff_von_neumann_iterator(H):
  tolerance = np.finfo(np.float).eps * 10
  (G, p) = H.pop(0)
  #remove edges with integer weights
  #extracts all edges satisfy the weight threshold (my_network is directed):
  eligible_edges = [(from_node,to_node,edge_attributes) for from_node,to_node,edge_attributes in G.edges(data=True) if all(i+tolerance < edge_attributes['weight'] or edge_attributes['weight'] < i - tolerance for i in range(0,5))]
  K = nx.DiGraph()
  K.add_edges_from(eligible_edges)
  #find a cycle and compute the push_forward and push_reverse probabilities and graphs
  cycle = nx.find_cycle(K, orientation='ignore')
  forward_weights = [(d['weight'],d['min_capacity'],d['max_capacity']) for (u,v,d) in K.edges(data=True) if (u,v,'forward') in cycle]
  reverse_weights = [(d['weight'],d['min_capacity'],d['max_capacity']) for (u,v,d) in K.edges(data=True) if (u,v,'reverse') in cycle]
  push_forward = min((x[2] - x[0] for x in forward_weights))
  push_reverse = min((x[2] - x[0] for x in reverse_weights))
  pull_forward = min((x[0] - x[1] for x in forward_weights))
  pull_reverse = min((x[0] - x[1] for x in reverse_weights))
  push_forward_pull_reverse = min(push_forward,pull_reverse)
  push_reverse_pull_forward = min(pull_forward,push_reverse)
  #Construct the push_forward_pull_reverse graph
  G1 = copy.deepcopy(G)
  for u,v,d in G1.edges(data=True):
    if (u,v,'forward') in cycle:
      d['weight']+=push_forward_pull_reverse
    if (u,v,'reverse') in cycle:
      d['weight']+=-push_forward_pull_reverse
  #Construct the push_reverse_pull_forward graph
  G2 = copy.deepcopy(G)
  for u,v,d in G2.edges(data=True):
    if (u,v,'reverse') in cycle:
      d['weight']+=push_reverse_pull_forward
    if (u,v,'forward') in cycle:
      d['weight']+=-push_reverse_pull_forward
  gamma = push_forward_pull_reverse/(push_forward_pull_reverse + push_reverse_pull_forward)
  return([(G1,p*gamma), (G2,p*(1-gamma))])

H=[(G,1)]
generalized_birkhoff_von_neumann_iterator(H)
</code>
</pre>
</font>
<p>  
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;10&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

 <p>

We now have the building blocks of python code to construct the directed graph from an expected assignment and constraint structure.

<br>
<br>

The followinng will find a bihierarchy if one exists

<font size="2">
<pre>
<code>
#takes the sets of a constraint structure and prints a bihierarchy if one exists
#e.g. C = [{(0, 1), (1, 1)}, {(1, 0), (0, 0)}, {(0, 1), (0, 0), (1, 1)}, {(0, 1), (1, 0), (0, 0)}]

import itertools
pc = itertools.permutations(C)

for c in pc:
  listofA, listofB = [], []
  for idx, x in enumerate(c):
    if all(x.issubset(y) or y.issubset(x) or x.isdisjoint(y) for y in [c[i] for i in listofA]):
      target = listofA
    elif all(x.issubset(z) or z.issubset(x) or x.isdisjoint(z) for z in [c[i] for i in listofB]):
      target = listofB
    else:
       print('stop')
       break
    target.append(idx)
  if len(listofA) + len(listofB) == len(c):
    print("A is %s and B is  %s  " % ([c[i] for i in listofA], [c[i] for i in listofB]))
    break
</code>
</pre>
</font>

Next we construct from the bihierarchy the two sides of the directed graph

<font size="2">
<pre>
<code>
#first add to each hierarchy the full set of object-agent pairs S and the singleton object-agent pairs

A.append(S), B.append(S)
for x in S:
  A.append({x}), B.append({x})
  
#construct each side of the directed graph
  
G1 = nx.DiGraph()
for x in A:
  for y in A:
    if x < y and not any(x < z < y for z in A):
      G1.add_edge(frozenset(y),frozenset(x))

G2 = nx.DiGraph()
for x in B:
  for y in B:
    if y < x and not any(y < z < x for z in B):
      G2.add_edge((frozenset(y),'p'),(frozenset(x),'p'))

#connect each side by combining G1 and G1 and construct the central column, adding weights using expected assignment X

G = nx.compose(G1,G2)

#now join the singleton object-agent edges and assign their weights
#e.g. X = np.array([[1, 2], [3, 4]])

for index, x in np.ndenumerate(X):
  G.add_edge(frozenset({index}), (frozenset({index}),'p'), weight=x)
</code>
</pre>
</font>

The final step is to use conservation of flow to fill in the remaining weights.

<p>
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;9&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>
 
<p>

This python code takes a list of sets and divides them into two groups. In the iteration, we take a set from the list and test if it is subset to or disjoint from all already collected sets <code>A</code>; if so it is added to <code>A</code>, if not  we do the same test with the already collected sets <code>B</code>. If the set can't be added to either <code>A</code> or <code>B</code>, 'stop' is printed. 

<br>
<br>

If a bihierarchy exists, this procedure will not always find it, and the printing of 'stop' neither implies or is implied by the constraint structure not being bihierarchy. If we consider all orderings of a constraint structure that is a bihierarchy we will find one where all the elements of one piece of the bihierarchy come before all elements of the other. The procedure will find this bihierarchy. 


<font size="2">
<pre>
<code>
C = [{(0, 1), (1, 1)}, {(1, 0), (0, 0)}, {(0, 1), (0, 0), (1, 1)}, {(0, 1), (1, 0), (0, 0)}]
C.sort(key=len)
C.reverse()
A=[]
B=[]

for x in C:
  if all(x.issubset(y) or y.issubset(x) or x.isdisjoint(y) for y in A):
    A.append(x)  
  elif all(x.issubset(z) or z.issubset(x) or x.isdisjoint(z) for z in B):
    B.append(x)   
  else:
    print('stop')
</code>
</pre>
</font>

<p>
 
 
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;8&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>
Given an expected assignment and constraint structure, want to construct a weighted directed graph from a source to a sink, first passing through nodes that are sets of object-agent pairs belonging to one piece of the bihierarchy, ordered by set inclusion from largest to smallest, and eventually reaching all nodes that are single object-agent pairs. The next part of the graph is its central column which passes from each singleton object-agent pair across to a replica node. The weight on this edge is the object-agent coordinate of the expected assignment. The graph then passes into the other piece of the bihierarchy, now entering small sets of object-agent pairs and then into their supersets, until terminally reaching the sink node. The source node is represented by the set of possible object-agent pairs, and the sink as its replica. Conservation of flow determines the edge weights.
<br>
<br>
First construct the central column

<font size="2">
<pre>
<code>
#implicitly use coordinates of X as labels for object-agent pairs

#X is an np.array e.g. X = np.array([[1, 2], [3, 4]])

D = nx.DiGraph()

for index, x in np.ndenumerate(X):
  D.add_edge(index, (index,'p'), weight=x)
</code>
</pre>
</font>

Now construct the two sides of the column from the constraint structure. Upper and lower bounds of the constraint structure wil be used to determine the dlows. For now we will work with only the subsets of object-agent pairs. Need to organize these subsets into a bihierarchy if possible. 
<br>
<br>
Start with two directed graphs and the list of subsets

<font size="2">
<pre>
<code>
G1 = nx.DiGraph()
G2 = nx.DiGraph()
C

#e.g. C = [{(0,0),(0,1),(1,1)}, {(0,1),(1,1)}, {(0,0),(1,0)}, {(0,0),(0,1),(1,0)}]
</code>
</pre>
</font>

Generate the full set of object-agent pairs

<font size="2">
<pre>
<code>
S = {index for index, x in np.ndenumerate(X)}
</code>
</pre>
</font>

I see two options for proceeding. One is to stop this approach and just work with <code>C</code>, iteratively dividing it into two pieces according to the rules of biheirarchy. Two is to order <code>C</code> by cardinality and to apply the same approach as one but try to construct the pieces of the directed graph in the process of seeing if the constraint structure is a bihierarchy.
  
<p>

<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;7&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  
 
 <p> 
  
One is given an expected assignment of objects to agents and a constraint structure specifying upper and lower bounds on the number of assignments per set of object-agent pairs. If the constraint structure is what <a href="http://faculty.chicagobooth.edu/eric.budish/research/Budish-Che-Kojima-Milgrom-2013-AER.pdf">Budish, Che, Kojima, and Milgrom 2013</a> call a <em>bihierarchy</em> then there exists a distribution over constraint abiding assignments that gives the expected assignment.
<br>
<br>
The first step of this algorithm represents the expected assignment and constraint structure as a weighted directed graph. The second step recursively invokes an algorithim on this graph, below implemented in python as <font size="2"><code>generalized_birkhoff_von_neumann_iterator()</code></font>, that decomposes expected assignments into pairs of expected assignments that are eventually pure assignments.
 
  
<font size="2">
<pre>
<code>
import networkx as nx
import numpy as np
import copy

#start with a list H of graphs and their probabilities

G = nx.DiGraph()
G.add_edge('S','s1',weight=1)
G.add_edge('S','w1',weight=0.3)
G.add_edge('S','w4',weight=0.7)
G.add_edge('w1','w1p',weight=0.3)
G.add_edge('w1p','Sp',weight=0.3)
G.add_edge('s1','w2',weight=0.7)
G.add_edge('s1','w3',weight=0.3)
G.add_edge('w2','w2p',weight=0.7)
G.add_edge('w2p','Sp',weight=0.7)
G.add_edge('w3','w3p',weight=0.3)
G.add_edge('w3p','s2',weight=0.3)
G.add_edge('s2','Sp',weight=1)
G.add_edge('w4','w4p',weight=0.7)
G.add_edge('w4p','s2',weight=0.7)
H = [(G,1)]

def generalized_birkhoff_von_neumann_iterator(H):

  tolerance = np.finfo(np.float).eps * 10
  
  (G, p) = H.pop(0)

  #remove integer weighted edges

  e = [(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] < tolerance or d['weight'] > 1-tolerance]
  G.remove_edges_from(e)

  #find a cycle and compute the push_forward and push_reverse probabilities and graphs

  cycle = nx.find_cycle(G, orientation='ignore')
  forward_weights = [d['weight'] for (u,v,d) in G.edges(data=True) if (u,v,'forward') in cycle]
  reverse_weights = [d['weight'] for (u,v,d) in G.edges(data=True) if (u,v,'reverse') in cycle]
  push_forward = 1 - max(forward_weights)
  push_reverse = 1-max(reverse_weights)
  pull_forward = min(forward_weights)
  pull_reverse = min(reverse_weights)
  push_forward_pull_reverse = min(push_forward,pull_reverse)
  push_reverse_pull_forward = min(pull_forward,push_reverse)

  #Construct the push_forward_pull_reverse graph

  G1 = copy.deepcopy(G)
  for u,v,d in G1.edges(data=True):
    if (u,v,'forward') in cycle:
      d['weight']+=push_forward_pull_reverse
    if (u,v,'reverse') in cycle:
      d['weight']+=-push_forward_pull_reverse
      
  #Construct the push_reverse_pull_forward graph

  G2 = copy.deepcopy(G)
  for u,v,d in G2.edges(data=True):
    if (u,v,'reverse') in cycle:
      d['weight']+=push_reverse_pull_forward
    if (u,v,'forward') in cycle:
      d['weight']+=-push_reverse_pull_forward

  H.extend([(G1,p*push_forward_pull_reverse), (G2,p*push_reverse_pull_forward)])

  return(H)
</code>
</pre>
</font>

<p>

<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;6&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

Each of you has been assigned a number 1 through 9, and each time has been assigned a letter A, B, or C. Preferences for times are as follows
  
  
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>2</td>
    <td>2</td>
    <td>1</td>
    <td>2</td>
    <td>2</td>
    <td>1</td>
    <td>1</td>
    <td>1</td>
    <td>3</td>
  </tr>
  <tr>
    <th>B</th>
    <td>1</td>
    <td>1</td>
    <td>3</td>
    <td>3</td>
    <td>1</td>
    <td>2</td>
    <td>2</td>
    <td>3</td>
    <td>1</td>
  </tr>
  <tr>
    <th>C</th>
    <td>3</td>
    <td>3</td>
    <td>2</td>
    <td>1</td>
    <td>3</td>
    <td>3</td>
    <td>3</td>
    <td>2</td>
    <td>2</td>
  </tr>
</table>

<br>

I will now describe the mechanism used to assign each of you to a time. 
<br>
<br>
Imagine that A, B, and C are actually cakes, each of size three. Individuals start eating their most preferred cake. Cake A is eaten by 3, 6, 7, and 8, cake B by 1, 2, 5, and 9, and cake C by 4. After 3/4 cake-eating time units, cakes A and B are finished, and 4 has eaten 3/4 units of cake C. All individuals but 4 now move to their second choice. Many, finding it no longer available, immediatly move to cake C. After 1/4 time, cake C is finished.
<br>
<br>
Here, cake is an analogy for probability mass so each individual gets the following probabilities of being assigned to one of A, B, or C
<br>
<br>

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>3/4</td>
    <td>3/4</td>
    <td>0</td>
  </tr>
  <tr>
    <th>B</th>
    <td>3/4</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
  </tr>
  <tr>
    <th>C</th>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
  </tr>
</table> 

<br>


Note that to achieve these probabilities we can't simply run a sequence of lotteries, one for each individual, since, for example, everyone might be assigned to C. What we have to do is run one lottery that assigns everyone at once. Fortunately, this is easily done by randomly selecting two individuals to join 4 at C. Everyone else gets their first choice. For example, if 8 and 9 were chosen then the allocation would be

<br>
<br>

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <th>B</th>
    <td>1</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <th>C</th>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>1</td>
  </tr>
</table>

<br>


By randomly selecting two people in this way we are actually randomly selecting one of 28 assignments (the number of ways to choose two individuals from eight), each chosen with probability 1/28.

<br>
<br>

This procedure is a generalized version of what is known as the <em>probabilistic serial mechanism</em>. See <a href="http://faculty.chicagobooth.edu/eric.budish/research/Budish-Che-Kojima-Milgrom-2013-AER.pdf">Budish, Che, Kojima, and Milgrom 2013</a>.


<p>





<br>










<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;5&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

\[

\gamma(d,\theta) = -\frac{1}{\pi(\theta)}\sum_{d',\theta}\frac{\partial^2 c(p)}{\partial p(d|\theta)\partial p(d'|\theta')}\lambda[d',\theta']

\]

Original explanation correct.
<br><br>
Types of problem with strong complementarities in information acquisiton. Set of stocks. If common stocks or stocks corellated in portfolios, can learn expected payoff for multiple decisions. Thus affect signal probability of one decision with learning about payoff of another.
<br><br>
Risk averse agent. Conjecture: make safe decision more risky rather than risky decision. Interaction with information acquisition. Limited liability infinite risk aversion at limit. Perhaps softer version previous explanation with Lagrange multiplier replaced by risk aversion. 
<p>





<br>








<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;4&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>


<p>

Desire delta \(f(p)\) at stock price \(p\). Suppose \(f\) decreasing and \(0\) at the initial price \(\bar p\). 

Take a sold put option on this stock with strike \(x\). Let \(g(p,x)\) denote the delta of this option. Likewise for a sold call option using \(h(p,x)\) and suppose their deltas as at expiry.

At each strike \(x<\bar p\) sell \(-f'(x)\Delta\) put options (where \(\Delta\) is the distance between strikes), and at each strike \(x>\bar p\) sell \(-f'(x)\Delta\) call options. 

At price \(p<\bar p\) delta of portfolio is
    
\[
\sum_{\{i: p \leq x_i \leq \bar p\}} -f'(x_i) \Delta g(p,x_i) = \sum_{\{i: p \leq x_i \leq \bar p\}} -f'(x_i) \Delta, 
\]
  <br>  
which converges as \(\Delta\) goes to \(0\) to \(\int_p^{\bar p} -f'(t)dt = f(p)\).

For price \(p>\bar p\) 
    
\[
\sum_{\{i: \bar p \leq x_i \leq p\}} -f'(x_i) \Delta h(p,x_i) = \sum_{\{i:\bar p \leq x_i \leq p\}} f'(x_i) \Delta, 
\]
  <br>  
converges as \(\Delta\) goes to \(0\) to \(\int_{\bar p}^p f'(t)dt = f(p)\).

For continuous strikes portfolio consists of infinitesimal quantity of each option.

<p>
  




</body>

</html>

