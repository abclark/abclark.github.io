<!DOCTYPE html>
<head>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG">
</script>
<head
<html lang="en" class="cufon-active cufon-ready"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>ยง</title>
  <link rel="stylesheet" href="../css/main.css" type="text/css" media="screen">
<style type="text/css">.cufon-canvas{text-indent:0!important;}@media screen,projection{.cufon-canvas{display:inline!important;display:inline-block!important;position:relative!important;vertical-align:middle!important;font-size:1px!important;line-height:1px!important;}.cufon-canvas .cufon-alt{display:-moz-inline-box!important;display:inline-block!important;width:0!important;height:0!important;overflow:hidden!important;text-indent:-10000in!important;}.cufon-canvas canvas{position:relative!important;}}@media print{.cufon-canvas{padding:0!important;}.cufon-canvas canvas{display:none!important;}.cufon-canvas .cufon-alt{display:inline!important;}}</style>
<style>
table, th, td {
    text-align: center;
}
</style>
<style>
p {
  margin-top: 0em;
  margin-bottom: 1.5em;
}
pre {
    white-space: pre-wrap;
}
</style>


<body>
  
<br><br><br>

  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;10&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>
 <p>

We now have the building blocks of python code to construct the directed graph from an expected assignment and constraint structure.

<br>
<br>

The followinng will find a bihierarchy if one exists

<font size="2">
<pre>
<code>
#takes the sets of a constraint structure and prints a bihierarchy if one exists
#e.g. C = [{(0, 1), (1, 1)}, {(1, 0), (0, 0)}, {(0, 1), (0, 0), (1, 1)}, {(0, 1), (1, 0), (0, 0)}]

import itertools
pc = itertools.permutations(C)

for c in pc:
  listofA, listofB = [], []
  for idx, x in enumerate(c):
    if all(x.issubset(y) or y.issubset(x) or x.isdisjoint(y) for y in [c[i] for i in listofA]):
      target = listofA
    elif all(x.issubset(z) or z.issubset(x) or x.isdisjoint(z) for z in [c[i] for i in listofB]):
      target = listofB
    else:
       print('stop')
       break
    target.append(idx)
  if len(listofA) + len(listofB) == len(c):
    print("A is %s and B is  %s  " % ([c[i] for i in listofA], [c[i] for i in listofB]))
    break
</code>
</pre>
</font>

Next we construct from the bihierarchy the two sides of the directed graph

<font size="2">
<pre>
<code>
#first add to each hierarchy the full set of object-agent pairs S and the singleton object-agent pairs

A.append(S), B.append(S)
for x in S:
  A.append({x}), B.append({x})
  
#construct each side of the directed graph
  
G1 = nx.DiGraph()
for x in A:
  for y in A:
    if x < y and not any(x < z < y for z in A):
      G1.add_edge(frozenset(y),frozenset(x))

G2 = nx.DiGraph()
for x in B:
  for y in B:
    if y < x and not any(y < z < x for z in B):
      G2.add_edge((frozenset(y),'p'),(frozenset(x),'p'))

#connect each side by combining G1 and G1 and construct the central column, adding weights using expected assignment X

G = nx.compose(G1,G2)

#now join the singleton object-agent edges and assign their weights
#e.g. X = np.array([[1, 2], [3, 4]])

for index, x in np.ndenumerate(X):
  G.add_edge(frozenset({index}), (frozenset({index}),'p'), weight=x)
</code>
</pre>
</font>

The final step is to use conservation of flow to fill in the remaining weights.

<p>
  
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;9&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>
 
<p>

This python code takes a list of sets and divides them into two groups. In the iteration, we take a set from the list and test if it is subset to or disjoint from all already collected sets <code>A</code>; if so it is added to <code>A</code>, if not  we do the same test with the already collected sets <code>B</code>. If the set can't be added to either <code>A</code> or <code>B</code>, 'stop' is printed. 

<br>
<br>

If a bihierarchy exists, this procedure will not always find it, and the printing of 'stop' neither implies or is implied by the constraint structure not being bihierarchy. If we consider all orderings of a constraint structure that is a bihierarchy we will find one where all the elements of one piece of the bihierarchy come before all elements of the other. The procedure will find this bihierarchy. 


<font size="2">
<pre>
<code>
C = [{(0, 1), (1, 1)}, {(1, 0), (0, 0)}, {(0, 1), (0, 0), (1, 1)}, {(0, 1), (1, 0), (0, 0)}]
C.sort(key=len)
C.reverse()
A=[]
B=[]

for x in C:
  if all(x.issubset(y) or y.issubset(x) or x.isdisjoint(y) for y in A):
    A.append(x)  
  elif all(x.issubset(z) or z.issubset(x) or x.isdisjoint(z) for z in B):
    B.append(x)   
  else:
    print('stop')
</code>
</pre>
</font>

<p>
 
 
<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;8&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>
Given an expected assignment and constraint structure, want to construct a weighted directed graph from a source to a sink, first passing through nodes that are sets of object-agent pairs belonging to one piece of the bihierarchy, ordered by set inclusion from largest to smallest, and eventually reaching all nodes that are single object-agent pairs. The next part of the graph is its central column which passes from each singleton object-agent pair across to a replica node. The weight on this edge is the object-agent coordinate of the expected assignment. The graph then passes into the other piece of the bihierarchy, now entering small sets of object-agent pairs and then into their supersets, until terminally reaching the sink node. The source node is represented by the set of possible object-agent pairs, and the sink as its replica. Conservation of flow determines the edge weights.
<br>
<br>
First construct the central column

<font size="2">
<pre>
<code>
#implicitly use coordinates of X as labels for object-agent pairs

#X is an np.array e.g. X = np.array([[1, 2], [3, 4]])

D = nx.DiGraph()

for index, x in np.ndenumerate(X):
  D.add_edge(index, (index,'p'), weight=x)
</code>
</pre>
</font>

Now construct the two sides of the column from the constraint structure. Upper and lower bounds of the constraint structure wil be used to determine the dlows. For now we will work with only the subsets of object-agent pairs. Need to organize these subsets into a bihierarchy if possible. 
<br>
<br>
Start with two directed graphs and the list of subsets

<font size="2">
<pre>
<code>
G1 = nx.DiGraph()
G2 = nx.DiGraph()
C

#e.g. C = [{(0,0),(0,1),(1,1)}, {(0,1),(1,1)}, {(0,0),(1,0)}, {(0,0),(0,1),(1,0)}]
</code>
</pre>
</font>

Generate the full set of object-agent pairs

<font size="2">
<pre>
<code>
S = {index for index, x in np.ndenumerate(X)}
</code>
</pre>
</font>

I see two options for proceeding. One is to stop this approach and just work with <code>C</code>, iteratively dividing it into two pieces according to the rules of biheirarchy. Two is to order <code>C</code> by cardinality and to apply the same approach as one but try to construct the pieces of the directed graph in the process of seeing if the constraint structure is a bihierarchy.
  
<p>

<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;7&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>  
 
 <p> 
  
One is given an expected assignment of objects to agents and a constraint structure specifying upper and lower bounds on the number of assignments per set of object-agent pairs. If the constraint structure is what <a href="http://faculty.chicagobooth.edu/eric.budish/research/Budish-Che-Kojima-Milgrom-2013-AER.pdf">Budish, Che, Kojima, and Milgrom 2013</a> call a <em>bihierarchy</em> then there exists a distribution over constraint abiding assignments that gives the expected assignment.
<br>
<br>
The first step of this algorithm represents the expected assignment and constraint structure as a weighted directed graph. The second step recursively invokes an algorithim on this graph, below implemented in python as <font size="2"><code>generalized_birkhoff_von_neumann_iterator()</code></font>, that decomposes expected assignments into pairs of expected assignments that are eventually pure assignments.
 
  
<font size="2">
<pre>
<code>
import networkx as nx
import numpy as np
import copy

#start with a list H of graphs and their probabilities

G = nx.DiGraph()
G.add_edge('S','s1',weight=1)
G.add_edge('S','w1',weight=0.3)
G.add_edge('S','w4',weight=0.7)
G.add_edge('w1','w1p',weight=0.3)
G.add_edge('w1p','Sp',weight=0.3)
G.add_edge('s1','w2',weight=0.7)
G.add_edge('s1','w3',weight=0.3)
G.add_edge('w2','w2p',weight=0.7)
G.add_edge('w2p','Sp',weight=0.7)
G.add_edge('w3','w3p',weight=0.3)
G.add_edge('w3p','s2',weight=0.3)
G.add_edge('s2','Sp',weight=1)
G.add_edge('w4','w4p',weight=0.7)
G.add_edge('w4p','s2',weight=0.7)
H = [(G,1)]

def generalized_birkhoff_von_neumann_iterator(H):

  tolerance = np.finfo(np.float).eps * 10
  
  (G, p) = H.pop(0)

  #remove integer weighted edges

  e = [(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] < tolerance or d['weight'] > 1-tolerance]
  G.remove_edges_from(e)

  #find a cycle and compute the push_forward and push_reverse probabilities and graphs

  cycle = nx.find_cycle(G, orientation='ignore')
  forward_weights = [d['weight'] for (u,v,d) in G.edges(data=True) if (u,v,'forward') in cycle]
  reverse_weights = [d['weight'] for (u,v,d) in G.edges(data=True) if (u,v,'reverse') in cycle]
  push_forward = 1 - max(forward_weights)
  push_reverse = 1-max(reverse_weights)
  pull_forward = min(forward_weights)
  pull_reverse = min(reverse_weights)
  push_forward_pull_reverse = min(push_forward,pull_reverse)
  push_reverse_pull_forward = min(pull_forward,push_reverse)

  #Construct the push_forward_pull_reverse graph

  G1 = copy.deepcopy(G)
  for u,v,d in G1.edges(data=True):
    if (u,v,'forward') in cycle:
      d['weight']+=push_forward_pull_reverse
    if (u,v,'reverse') in cycle:
      d['weight']+=-push_forward_pull_reverse
      
  #Construct the push_reverse_pull_forward graph

  G2 = copy.deepcopy(G)
  for u,v,d in G2.edges(data=True):
    if (u,v,'reverse') in cycle:
      d['weight']+=push_reverse_pull_forward
    if (u,v,'forward') in cycle:
      d['weight']+=-push_reverse_pull_forward

  H.extend([(G1,p*push_forward_pull_reverse), (G2,p*push_reverse_pull_forward)])

  return(H)
</code>
</pre>
</font>

<p>

<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;6&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

Each of you has been assigned a number 1 through 9, and each time has been assigned a letter A, B, or C. Preferences for times are as follows
  
  
<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>2</td>
    <td>2</td>
    <td>1</td>
    <td>2</td>
    <td>2</td>
    <td>1</td>
    <td>1</td>
    <td>1</td>
    <td>3</td>
  </tr>
  <tr>
    <th>B</th>
    <td>1</td>
    <td>1</td>
    <td>3</td>
    <td>3</td>
    <td>1</td>
    <td>2</td>
    <td>2</td>
    <td>3</td>
    <td>1</td>
  </tr>
  <tr>
    <th>C</th>
    <td>3</td>
    <td>3</td>
    <td>2</td>
    <td>1</td>
    <td>3</td>
    <td>3</td>
    <td>3</td>
    <td>2</td>
    <td>2</td>
  </tr>
</table>

<br>

I will now describe the mechanism used to assign each of you to a time. 
<br>
<br>
Imagine that A, B, and C are actually cakes, each of size three. Individuals start eating their most preferred cake. Cake A is eaten by 3, 6, 7, and 8, cake B by 1, 2, 5, and 9, and cake C by 4. After 3/4 cake-eating time units, cakes A and B are finished, and 4 has eaten 3/4 units of cake C. All individuals but 4 now move to their second choice. Many, finding it no longer available, immediatly move to cake C. After 1/4 time, cake C is finished.
<br>
<br>
Here, cake is an analogy for probability mass so each individual gets the following probabilities of being assigned to one of A, B, or C
<br>
<br>

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>3/4</td>
    <td>3/4</td>
    <td>0</td>
  </tr>
  <tr>
    <th>B</th>
    <td>3/4</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>3/4</td>
  </tr>
  <tr>
    <th>C</th>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
    <td>1/4</td>
  </tr>
</table> 

<br>


Note that to achieve these probabilities we can't simply run a sequence of lotteries, one for each individual, since, for example, everyone might be assigned to C. What we have to do is run one lottery that assigns everyone at once. Fortunately, this is easily done by randomly selecting two individuals to join 4 at C. Everyone else gets their first choice. For example, if 8 and 9 were chosen then the allocation would be

<br>
<br>

<table align="center" style="width:50%">
  <tr>
    <th> </th>
    <th>1</th>
    <th>2</th>
    <th>3</th>
    <th>4</th>
    <th>5</th>
    <th>6</th>
    <th>7</th>
    <th>8</th>
    <th>9</th>
  </tr>
  <tr>
    <th>A</th>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <th>B</th>
    <td>1</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <th>C</th>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>0</td>
    <td>0</td>
    <td>0</td>
    <td>1</td>
    <td>1</td>
  </tr>
</table>

<br>


By randomly selecting two people in this way we are actually randomly selecting one of 28 assignments (the number of ways to choose two individuals from eight), each chosen with probability 1/28.

<br>
<br>

This procedure is a generalized version of what is known as the <em>probabilistic serial mechanism</em>. See <a href="http://faculty.chicagobooth.edu/eric.budish/research/Budish-Che-Kojima-Milgrom-2013-AER.pdf">Budish, Che, Kojima, and Milgrom 2013</a>.


<p>





<br>










<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;5&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>

<p>

\[

\gamma(d,\theta) = -\frac{1}{\pi(\theta)}\sum_{d',\theta}\frac{\partial^2 c(p)}{\partial p(d|\theta)\partial p(d'|\theta')}\lambda[d',\theta']

\]

Original explanation correct.
<br><br>
Types of problem with strong complementarities in information acquisiton. Set of stocks. If common stocks or stocks corellated in portfolios, can learn expected payoff for multiple decisions. Thus affect signal probability of one decision with learning about payoff of another.
<br><br>
Risk averse agent. Conjecture: make safe decision more risky rather than risky decision. Interaction with information acquisition. Limited liability infinite risk aversion at limit. Perhaps softer version previous explanation with Lagrange multiplier replaced by risk aversion. 
<p>





<br>








<p>
<BIG>
O&nbsp;C&nbsp;T&nbsp;O&nbsp;B&nbsp;E&nbsp;R&nbsp;&nbsp;&nbsp;4&nbsp;t&nbsp;h&nbsp;&nbsp;&nbsp;2&nbsp;0&nbsp;1&nbsp;7</BIG>
</p>


<p>

Desire delta \(f(p)\) at stock price \(p\). Suppose \(f\) decreasing and \(0\) at the initial price \(\bar p\). 

Take a sold put option on this stock with strike \(x\). Let \(g(p,x)\) denote the delta of this option. Likewise for a sold call option using \(h(p,x)\) and suppose their deltas as at expiry.

At each strike \(x<\bar p\) sell \(-f'(x)\Delta\) put options (where \(\Delta\) is the distance between strikes), and at each strike \(x>\bar p\) sell \(-f'(x)\Delta\) call options. 

At price \(p<\bar p\) delta of portfolio is
    
\[
\sum_{\{i: p \leq x_i \leq \bar p\}} -f'(x_i) \Delta g(p,x_i) = \sum_{\{i: p \leq x_i \leq \bar p\}} -f'(x_i) \Delta, 
\]
  <br>  
which converges as \(\Delta\) goes to \(0\) to \(\int_p^{\bar p} -f'(t)dt = f(p)\).

For price \(p>\bar p\) 
    
\[
\sum_{\{i: \bar p \leq x_i \leq p\}} -f'(x_i) \Delta h(p,x_i) = \sum_{\{i:\bar p \leq x_i \leq p\}} f'(x_i) \Delta, 
\]
  <br>  
converges as \(\Delta\) goes to \(0\) to \(\int_{\bar p}^p f'(t)dt = f(p)\).

For continuous strikes portfolio consists of infinitesimal quantity of each option.

<p>
  




</body>

</html>

