<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_SVG"></script>

<h1 align="center">Contracts for Experimentation</h1>
<h3 align="center">Author: Aubrey Clark</h3>
<h3 align="center"> First version: May 2014. This version: June 2017</h3>

<em>
 
<p>This paper investigates contracts that provide incentives for information acquisition that is costly for an agent and unobservable to a principal. We show that every Pareto optimal contract pays a fraction of output, a state-dependent transfer, and a decision-dependent transfer. </p> 
  
<p>The fraction of output is increasing in the set of experiments to the agent can choose. The state-dependent transfer indexes contract payments to account for differences in output between states. The decision-dependent transfer punishes decisions that are likely to result in binding liability limits.</p>

</em>

<h2>Introduction</h2>

Desiring to learn the state of the world a principal hires an expert agent to generate data. Unfortunately for the principal he cannot directly observe the agent's selection of data generating process. The principal therefore ties compensation to verifiable information that is correllated with the agent's choice.<br><br>

For example, let's say that the principal is someone trying to decide where to invest their savings in the stock market, and that the agent is a financial advisor or professional investor promising to provide information about the markets and suggestions on where to invest. A compensation scheme might depend on the suggested portfolio of stocks and their terminal prices.<br><br>

Consider a principal that wishes to hire an agent to acquire information and take a decision on his behalf. The nature of the information to be acquired precludes verifying how carefully the agent carries out this task, but the pair can enforce a contract stipulating transfers as a function of the decision the agent takes and the realized state of the world. Information is costly for the agent and he is capacity constrained in the amount he can acquire. Both parties are risk-neutral and transfers between them are constrained by liability limits.<br><br>

We show that each Pareto optimal contract pays a fraction of output, a state-dependent transfer, and---with information costs proportional to expected Shannon entropy reduction---a decision dependent transfer. The fraction of output is increasing in the set of experiments available to the agent, the state-dependent transfer indexes contract payments to differences in output between states, and the decision-dependent transfer punishes decisions likely to make liability limits bind.<br><br>
 
The resulting contract can be described simply: stipulation of the liability limits, a punishment or reward for each decision based on its ex-ante risk of causing bankruptcy, an indexing payment so the agent is not rewarded purely for finding himself in a lucky state, and a piece rate based on the agent's capacity for acquiring information.<br><br>

For a general cost function the expression that becomes decision-dependent under expected Shannon entropy reduction sheds light on how optimal incentives are shaped by complementarities in the cost of acquiring information. If a contract payment is stuck against a liability limit, then other contract payments substitute for its role of influencing the signal probability. This depends on the complementarities in the cost of acquiring different signals in different states.<br><br>

The rest of the paper is organized as follows. We lay out the model in section~\ref{framework}. Section~\ref{Results} contains the analysis and results, and is divided into six parts: in section~\ref{First-best contracts} we characterize the Pareto optimal contracts that are first-best; in section~\ref{CapacityConstraint} we present a method for dealing with the capacity constraint, allowing subsequent analysis to do without it; section~\ref{Second-best contracts} studies the form of Pareto optimal contracts that are second-best; section~\ref{pieceindexationoptimaldistortion} discusses how the previous three sections work together to characterize the set of Pareto optimal contracts; in section~\ref{posteriorseparablecost} we consider the contract forms arising from different cost functions and discuss the simplest way of describing the optimal contract; and in section~\ref{multiball} we present a multi-period model. We discuss applications and relations to other contract forms in the literature in section~\ref{Discussion}; in section~\ref{Summary} we conclude. All proofs and derivations are collected in appendix~\ref{proofs}, and appendix~\ref{graphicalexample} solves a simple example and presents a graphical method for analyzing the optimal contract.<br><br>

<h2>Related literature</h2>

The first study of optimal incentives for information acquisition was completed by Demski and Sappington~\cite{demski1987delegated}. They focused on optimal risk-sharing arrangements and on contracts that depend solely on output. Their main concern was the interaction between the ``planning phase'' (the acquiring of information) and the ``implementation phase'' (the choice of a decision). Their basic point was that, even if implementation is costless (as it is in our model), the unverifiable nature of planning induces moral hazard in implementation since the outcome of the agent's decision provides information about his planning.<br><br>

Osband~\cite{osband1989optimal} was led to the problem from his study of proper scoring rules---incentive schemes that elicit true beliefs (see~\cite{savage1971elicitation}). His goal was to characterize the best proper scoring rule eliciting a forecaster's estimate of the mean of a random variable. The forecaster draws observations of the random variable at a cost, and this cost as well as the number of observations the forecaster makes are unknown to the principal. His focus was on the merits of (a) screening by offering a menu of contracts versus (b) pitting forecasters in competition against one another.<br><br>

More recently, Zerme{\~n}o~\cite{zermeno2011principal,zermeno2012role} has developed a very general model of incentivizing information acquisition under liability limits. His analysis focuses on the interaction between the verifiable data on which a contract can depend (for instance, the decision may be verifiable but the state may not be) and: (1) the usefulness of menus of contracts, and (2) whether the principal or agent is tasked to take the decision. Menus are useful because they allow contract payments to partially depend on the state: following receipt of a signal the agent gets to choose a decision and a contract from the menu; since the signal is correlated with the state the menu functions as a tool for correlating contract payments with the state---a role that is otherwise forced upon the agent's choice of decision---with a more precise signal leading to better correlation. In general, menus do not allow perfect correlation between contract payments and the state, and for this reason decision making is usually ex-post inefficient---it is distorted so that the agent is more likely to take a decision that reveals the state. Regarding (2), the allocation of decision making authority is irrelevant when the principal and agent can infer from the verifiable data which decision was taken; when this is unclear, whether the principal or agent is tasked to take the decision affects the set of implementable outcomes.<br><br>

Carroll~\cite{Carroll16} builds on and refines this model to study the form of ``robust'' incentives for information acquisition: a principal does not know all experiments or experiment costs available to an agent and ranks contracts according to their minimum expected payoff among all experiments and experiment costs including a known set. He shows that the optimal contract is a \emph{restricted investment contract}: the set of decisions available to the agent is restricted, and for unrestricted decisions the optimal contract pays a fraction of output and a state-dependent transfer.<br><br>

Our paper falls closest to Carroll's. In the terminology of our model, one may view Carroll's restriction on decisions as resulting from a decision-dependent transfer that severely punishes restricted decisions. From this perspective, the contracts we find generalize restricted investment contracts. This provides a link between Bayesian and non-Bayesian approaches to designing incentives for experimentation.<br><br>

<h2>The Model</h2>

It is helpful to split up the timing of the model into two dates. At date $0$, a principal faces a choice from a finite set of \emph{decisions} $D$. The date $1$ payoff to the principal from a decision depends on the realization of one among a finite set of \emph{states} $\Theta$, as described by an \emph{output function} $y:D \times \Theta \to \BR$. The principal hires an agent to acquire information about the state and take a decision on his behalf but cannot either monitor how much care the agent takes acquiring information or observe the information the agent does acquire. The principal motivates the agent with a \emph{contract} $b:D \times \Theta \to \BR$ that depends on the decision the agent takes and the realized state of the world---both are verifiable.

At date $0$, the principal and agent agree to a contract $b$. At date $1$, before choosing a decision, the agent performs an \emph{experiment} $(X,\{p(\cdot| \theta)\}_{\theta \in \Theta})$, which consists of a finite set of \emph{signals} $X$ and a collection of probability distributions $\{p(\cdot|\theta)\}_{\theta \in \Theta} \subseteq \Delta(X)$ on the set of signals. A \emph{decision rule} $f:X\to \Delta(D)$ describes the agent's randomization over decisions upon observing each signal. 

An \emph{action profile} $(b,X,\{p(\cdot|\theta)\}_{\theta\in \Theta},f)$ consists of a contract, experiment, and decision rule. The agent has preferences over action profiles $(b,X,\{p(\cdot|\theta)\}_{\theta\in \Theta},f)$ given by the expected value of contract payments less an experiment cost: 
%
\begin{equation*}
\sum_{\theta\in \Theta}\pi(\theta)\sum_{x\in X}p(x|\theta)\sum_{d\in D}f(d|x)b(d,\theta)-c(X,\{p(\cdot|\theta)\}_{\theta\in \Theta}).
\end{equation*} 
%
The distribution $\pi\in \Delta(\Theta)$ is the agent's \emph{prior belief} over states and the function $c$ is the agent's \emph{cost function}. For now, the cost function is only assumed to respect the ordering of experiments given by informativeness (see Blackwell's theorem\footnote{Experiment $(X,\{p(\cdot|\theta)\}_{\theta\in \Theta})$ is \emph{more informative} than experiment $(X',\{p'(\cdot|\theta)\}_{\theta\in \Theta})$ if for any prior $\pi$ and contract $b$, whenever some expected payoff can be achieved under the latter experiment, then it can be achieved under the former. That is, for each decision rule $f'$ on $X'$ there exists a decision rule $f$ on $X$ such that 
%
\[\sum_{\theta\in \Theta}\pi(\theta)\sum_{x'\in X'}p'(x'|\theta)\sum_{d\in D}f'(d|x')b(d,\theta) = \sum_{\theta\in \Theta}\pi(\theta)\sum_{x\in X}p(x|\theta)\sum_{d\in D}f(d|x)b(d,\theta).\]
%

Experiment $(X,\{p(\cdot|\theta)\}_{\theta\in \Theta})$ is \emph{sufficient} for experiment $(X',\{p'(\cdot|\theta)\}_{\theta\in \Theta})$ if there is a \emph{garbling function} $g:X \to \Delta(X')$ such that 
%
\[p'(x'|\theta) = \sum_{x\in X}p(x|\theta)g(x'|x).\] 
%
That is, experiment $(X',\{p'(\cdot|\theta)\}_{\theta\in \Theta})$ can be performed by randomizing over its outcomes according to $g$ where the randomization depends on the outcome of the experiment $(X,\{p(\cdot|\theta)\}_{\theta\in \Theta})$.

\emph{Blackwell's theorem} \cite{blackwell1953equivalent} states that an experiment is more informative than  another if and only if it is sufficient.\label{footnote1}}).


The principal has preferences over action profiles $(b,X,\{p(\cdot|\theta)\}_{\theta\in \Theta},f)$ given by the expected value of output less contract payments:
%
\begin{equation*}
\sum_{\theta\in \Theta}\pi(\theta)\sum_{x\in X}p(x|\theta)\sum_{d\in D}f(d|x)\left(y(d,\theta)-b(d,\theta)\right).
\end{equation*} 
%

Contracts are restricted to belong to a set $\mathscr{B}$ of \emph{feasible contracts} and experiments are restricted to belong to a set $\mathscr{E}$ of \emph{feasible experiments}. 

A contract $b$ satisfies the \emph{limited liability} constraints if $0\leq b(d,\theta)\leq y(d,\theta)$ for all $d\in D,\theta\in \Theta$. The set of feasible contracts are those satisfying the limited liability constraints. This may mean that the principal and agent are wealth constrained (with wealth normalized to zero or included in output $y$) or that the contract is subject to statutory liability limits (as is the case for a limited liability corporation).

In addition to the incremental cost of acquiring information represented by the cost function $c$, we assume that the agent faces a \emph{capacity constraint} $c(X,\{p(\cdot|\theta)\}_{\theta\in\Theta})\leq k$ that limits the experiments he can perform. The set of feasible experiments are those satisfying this constraint.

An action profile $(b,X,\{p(\cdot|\theta)\}_{\theta \in \Theta},f)$ is \emph{feasible} if the contract $b$ and experiment $(X,\{p(\cdot|\theta)\}_{\theta \in \Theta})$ are feasible, and there is no action profile $(b,X',\{p'(\cdot|\theta)\}_{\theta\in \Theta},f')$, consisting of the same contract and some feasible experiment, that the agent prefers. 

An action profile can be \emph{improved upon} if there is a feasible profile that makes either the agent or principal better off without making the other worse off. An action profile is \emph{Pareto optimal} if it is feasible and cannot be improved upon.

\paragraph{Normalizing the experiment and decision rule.}\label{normalize}

A decision rule is a garbling function (see footnote~\ref{footnote1}). Thus, given action profile $(b,X,\{p(\cdot| \theta)\}_{\theta\in \Theta},f)$, we may define a garbled experiment $(D,\{p'(\cdot|\theta)\}_{\theta\in \Theta})$ by $p'(d|\theta) = \sum_{x\in X}p(x|\theta)f(d|x)$ and choose the decision rule $f':D\to \Delta(D)$ that maps each decision to the degenerate distribution on that decision. The contract has the same expected payoff under this experiment and decision rule and since the former experiment is sufficient for the latter it is weakly more costly. Thus, it is without loss to set the agent's set of signals to be $D$ and the agent's decision rule $f: D\to \Delta(D)$ to map each decision to the degenerate distribution on that decision.

Given this normalization, we will write $p$ for the experiment $(D,\{p(\cdot | \theta)\}_{\theta\in \Theta})$, and write $(b,p)$ for the action profile $(b, D,\{p(\cdot | \theta)\}_{\theta\in \Theta},f)$ in which $f$ maps each decision to the degenerate distribution on that decision. We will write $E_p[b]-c(p)$ and $E_p[y-b]$ for the agent's and principal's utility from action profile $(b,p)$. For experiment $p$, we will write $p(d,\theta)$ for the joint probability $p(d|\theta)\pi(\theta)$, $p(d)$ for the total probability $\sum_\theta \pi(\theta)p(d|\theta)$, and $p(\theta|d)$ for the posterior probability $p(d|\theta)\pi(\theta)/\sum_{\theta'} \pi(\theta')p(d|\theta')$.

 
 

